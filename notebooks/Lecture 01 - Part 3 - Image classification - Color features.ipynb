{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe3d21e8-0024-4db3-b1c7-9cc177a81dd5",
   "metadata": {},
   "source": [
    "# **SIN 393 – Introduction to Computer Vision (2023-2)**\n",
    "\n",
    "# Lecture 01 - Part 3 - Image classification - color features\n",
    "\n",
    "Prof. João Fernando Mari ([*joaofmari.github.io*](https://joaofmari.github.io/))\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82b04ad0-3538-44ce-8f8b-4440ee0d06b0",
   "metadata": {},
   "source": [
    "## Importing the required libraries\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "53964247-db4c-4a85-9a10-8b3446826d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "from skimage import util, transform, filters, color, measure, morphology, io, exposure\n",
    "from sklearn import model_selection, neighbors, metrics, preprocessing\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "### %matplotlib notebook\n",
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c3f97cf-a7f2-4bc6-a076-de8c3158d337",
   "metadata": {},
   "source": [
    "## The dataset \n",
    "---\n",
    "* Flowers detection dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1affc770-db66-4d5c-8634-fdf18d587e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3 classes - 50 images in these classes\n",
    "ds_path = 'data/flowers_toy'\n",
    "\n",
    "# 3 classes - 6 images per class\n",
    "#### ds_path = 'data/flowers_toy2'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f12f68a-06e2-427b-a605-a7753953bfb5",
   "metadata": {},
   "source": [
    "### ***** Renomear os arquivos. Executar somente na primeira vez *****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e750a35-f5b1-4955-a95f-9e2e18faae14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ***** Renomeia os arquivos. Executar somente uma vez *****\n",
    "\n",
    "# # Iterate along the classes of the dataset\n",
    "# for classe in classes_list:\n",
    "#     # Listagem de todas as imagens na pasta daquela classe\n",
    "#     filename_list = os.listdir(os.path.join(ds_path, classe))\n",
    "#     filename_list.sort()\n",
    "    \n",
    "#     # Percorre os arquivos na pasta atual\n",
    "#     for i, filename in enumerate(filename_list):\n",
    "#         os.rename(os.path.join(ds_path, classe, filename), \n",
    "#                   os.path.join(ds_path, classe, f'{classe}{i:03}.{filename.split(\".\")[-1]}'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c49cfa77-ec8d-43c0-94b4-220070e616ec",
   "metadata": {},
   "source": [
    "## Loading the images from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8179520d-9066-419c-9ddf-8b77cd7fccf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of all folders in the folder 'ds_path' (classes)\n",
    "classes_list = os.listdir(ds_path)\n",
    "\n",
    "# List of all images in the dataset\n",
    "image_list = []\n",
    "# Lista of the image labels\n",
    "label_list = []\n",
    "\n",
    "# List of the image names\n",
    "filename_list_ = []\n",
    "\n",
    "# Iterate along the classes of the dataset\n",
    "for classe in classes_list:\n",
    "    \n",
    "    # Listagem de todas as imagens na pasta daquela classe\n",
    "    filename_list = os.listdir(os.path.join(ds_path, classe))\n",
    "\n",
    "    filename_list.sort()\n",
    "    \n",
    "    # Percorre os arquivos na pasta atual\n",
    "    for filename in filename_list:\n",
    "        # Load the image\n",
    "        img_temp = io.imread(os.path.join(ds_path, classe, filename))\n",
    "        \n",
    "        # Redimensiona a imagem para 64 x 64 \n",
    "        img_temp = transform.resize(img_temp, (64, 64), anti_aliasing=True)\n",
    "        \n",
    "        # Append the image to a list\n",
    "        image_list.append(img_temp)\n",
    "        # Append the label to a list\n",
    "        label_list.append(classe)\n",
    "        # Append the file name to a list (para fins de visualização)\n",
    "        filename_list_.append(filename)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a463eefc",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_list = np.array(label_list)\n",
    "\n",
    "# Lista com os rótulos das imagens        \n",
    "print(label_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21b97857-a1c2-4555-a81f-198175ea73b1",
   "metadata": {},
   "source": [
    "### Plotting the dataset images\n",
    "\n",
    "* Plotting the N first images for each class.\n",
    "* Important to start understanding the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7677065b-66c5-46ff-816a-9c21a7abcd49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seleciona apenas as primeiras N imagens de cada classe\n",
    "image_list_temp = []\n",
    "filename_list_temp = []\n",
    "\n",
    "# Itera pelo número de classes\n",
    "for i in range(3):\n",
    "    print(i, classes_list[i])\n",
    "    # As 6 primeiras ocorrencias em que label é igual a 'i'.\n",
    "    image_list_temp += [image_list[j] for j in np.where(label_list==classes_list[i])[0][:6]]\n",
    "    filename_list_temp += [filename_list_[j] for j in np.where(label_list==classes_list[i])[0][:6]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d584b38-8f8c-4b73-9d70-0b531f122a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax  = plt.subplots(3, 6, figsize=(9, 5))\n",
    "\n",
    "for i, (image, filename) in enumerate(zip(image_list_temp, filename_list_temp)):\n",
    "    ax[i//6, i%6].imshow(image, vmin=0, vmax=255)\n",
    "    ax[i//6, i%6].set_title(str(filename), fontsize=10)\n",
    "    ax[i//6, i%6].axis('off')\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04caf5a1-c029-4dcf-a41c-6b65dbded6ae",
   "metadata": {},
   "source": [
    "## Extracting some color based features from images\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a92cd72-2506-43dc-92a0-ca61d82484d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2D array with the images features\n",
    "# Each line stores information about an image. Each column stores one feature.\n",
    "feature_mat = []\n",
    "\n",
    "# Number of histogram bins \n",
    "n_bins = 32\n",
    "\n",
    "for i, (image, label) in enumerate(zip(image_list, label_list)):\n",
    "    # DEBUG\n",
    "    print('Imagem {} - classe {}'.format(i, label))\n",
    "    \n",
    "    # Convert the image data type to float\n",
    "    # img_float = util.img_as_float(image)\n",
    "    img_float = image\n",
    "\n",
    "    # Compute the histogram for each channel\n",
    "    hist_r = exposure.histogram(img_float[:,:,0], nbins=n_bins)[0]\n",
    "    hist_g = exposure.histogram(img_float[:,:,1], nbins=n_bins)[0]\n",
    "    hist_b = exposure.histogram(img_float[:,:,2], nbins=n_bins)[0]\n",
    "\n",
    "    # Concatenet the histogramns in one single feature vector\n",
    "    feat_hist = np.concatenate((hist_r, hist_g, hist_b))\n",
    "    ### print(feat_hist)\n",
    "\n",
    "    # Append the feature vector to the feature matrix\n",
    "    feature_mat.append(feat_hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "566912cf-ff4e-4e01-b739-a902ea884a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converte a lista de caracteristicas para um arranjo NumPy\n",
    "feature_mat = np.array(feature_mat)\n",
    "\n",
    "# Shape of the feature_map.\n",
    "# Each row is a sample (image), and each column is a feature.\n",
    "print(feature_mat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0ebf516-d632-4ba2-8133-fef92305cd64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Algumas estatisticas sobre o conjunto de caracteristicas\n",
    "with np.printoptions(precision=4, suppress=True):\n",
    "    print('Histogram minimum values:')\n",
    "    print(feature_mat.min(0))\n",
    "    print('Histogram maximum values:')\n",
    "    print(feature_mat.max(0))\n",
    "    print('Histogram mean values:')\n",
    "    print(feature_mat.mean(0))\n",
    "    print('Histogram standard deviation values:')\n",
    "    print(feature_mat.std(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9e01283-0e6e-4fab-b2c4-9af42c4e0095",
   "metadata": {},
   "source": [
    "### Plotando as caracteristicas computadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ab96298c-522f-4ac8-976b-bf575f8642ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seleciona apenas as primeiras N imagens de cada classe\n",
    "feature_mat_temp = []\n",
    "filename_list_temp = []\n",
    "\n",
    "# Itera pelo número de classes\n",
    "for i in range(3):\n",
    "    # As 6 primeiras ocorrencias em que label é igual a 'i'.\n",
    "    feature_mat_temp += [feature_mat[j] for j in np.where(label_list==classes_list[i])[0][:3]]\n",
    "    filename_list_temp += [filename_list_[j] for j in np.where(label_list==classes_list[i])[0][:3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0825c928-0b2c-4d07-a04a-7deefbcce247",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax  = plt.subplots(3, 3, figsize=(9, 5))\n",
    "\n",
    "for i, (feature, filename) in enumerate(zip(feature_mat_temp, filename_list_temp)):\n",
    "    ## ax[i//6, i%6].imshow(image, vmin=0, vmax=255)\n",
    "    ax[i//3, i%3].plot(feature)\n",
    "    ax[i//3, i%3].set_title(str(filename), fontsize=10)\n",
    "    ### ax[i//6, i%6].axis('off')\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9910a554-1b54-4633-aaaf-f5db819c98ef",
   "metadata": {},
   "source": [
    "## Cross-validation - Hold-out\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bede10eb-52d6-4ac0-81db-faff18cee647",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecionamos apenas duas caracteristicas: Área e maior-eixo\n",
    "feature_mat_ok = feature_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2a278b66-89b4-4590-bf6a-532cf91424ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separa 20% do conjuto de completo para TESTES. 80% para treinamento 1.\n",
    "X_train_1, X_test, y_train_1, y_test, file_train_1, file_test = model_selection.train_test_split(feature_mat_ok, \n",
    "                                                                                                 label_list, \n",
    "                                                                                                 filename_list_,\n",
    "                                                                                                 test_size=0.2, \n",
    "                                                                                                 stratify=label_list,\n",
    "                                                                                                 random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "55b4fec0-67c5-423b-b1fd-f948d1d3c8eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separa 25% do conjuto de treinamento 1 para validação.\n",
    "#   -> Equivale a 20% do conjunto completo. 0,2 / 0,8 = 0,25\n",
    "X_train_2, X_val, y_train_2, y_val, file_train_2, file_val = model_selection.train_test_split(X_train_1, \n",
    "                                                                                              y_train_1, \n",
    "                                                                                              file_train_1,\n",
    "                                                                                              test_size=0.25, \n",
    "                                                                                              stratify=y_train_1,\n",
    "                                                                                              random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03e75246-0104-4222-91e7-18619497ae60",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(X_train_2))\n",
    "print(len(X_val))\n",
    "print(len(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "996e6ca6-b4f5-49c9-90b0-fbf6634ef3a9",
   "metadata": {},
   "source": [
    "## Feature normalization\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6810d6b7-d2f4-4498-b7e1-cbc2b80cd10b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Média das caracteristicas do conjunto de treinamento\n",
    "X_train_2_mean = X_train_2.mean(0)\n",
    "\n",
    "# Desvio padrão das caracteristicas do conjunto de treinamento\n",
    "X_train_2_std = X_train_2.std(0)\n",
    "\n",
    "with np.printoptions(precision=4, suppress=True):\n",
    "    print(X_train_2.mean(0))\n",
    "    print(X_train_2.std(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97c5b61d-8b9f-4b84-8c32-e0c35c86bb24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformada Normal de Caracteristicas (Manual)\n",
    "# ----\n",
    "# X_train_2_norm = (X_train_2 - X_train_2_mean) / X_train_2_std\n",
    "# X_val_norm = (X_val - X_train_2_mean) / X_train_2_std\n",
    "# X_test_norm = (X_test - X_train_2_mean) / X_train_2_std\n",
    "\n",
    "# Transformada Normal de Caracteristicas (Sklearn)\n",
    "# ----\n",
    "scaler = preprocessing.StandardScaler().fit(X_train_2)\n",
    "with np.printoptions(precision=4, suppress=True):\n",
    "    print(f'Média:  \\t {np.array(scaler.mean_)}')\n",
    "    print(f'Desv. pad.: \\t {np.array(scaler.scale_)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5745a2e7-088e-4072-9d48-fd3c43c86b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_2_norm = scaler.transform(X_train_2)\n",
    "X_val_norm = scaler.transform(X_val)\n",
    "X_test_norm = scaler.transform(X_test)\n",
    "\n",
    "with np.printoptions(precision=4, suppress=True):\n",
    "    print(f'Treino: \\t {X_train_2_norm.mean():.4f} ± {X_train_2_norm.std():.4f}')\n",
    "    print(f'Validação: \\t {X_val_norm.mean():.4f} ± {X_val_norm.std():.4f}')\n",
    "    print(f'Teste:   \\t {X_test_norm.mean():.4f} ± {X_test_norm.std():.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7fa1958-5eeb-4ec0-b30c-53c855b93f98",
   "metadata": {},
   "source": [
    "## Optimizing hyperparameters in the validation set\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "70ab49b9-dc96-4eeb-80f8-1b48564bff11",
   "metadata": {},
   "outputs": [],
   "source": [
    "k_list = [1, 3, 5, 7, 9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b167f227-69ac-4f11-bdc1-42b552222880",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista com as acurácias de traino\n",
    "acc_train_list = []\n",
    "# Lista com as acurácias de validação\n",
    "acc_val_list = []\n",
    "\n",
    "for k_ in k_list:\n",
    "    # Constrói um classificador K-NN. K = k_\n",
    "    clf = neighbors.KNeighborsClassifier(n_neighbors=k_, n_jobs=1)\n",
    "\n",
    "    # Treinando o classificador\n",
    "    clf.fit(X_train_2_norm, y_train_2)\n",
    "\n",
    "    # Testando o classificador (usando o conjunto de validação)\n",
    "    pred = clf.predict(X_val_norm)\n",
    "    acc_val = metrics.accuracy_score(y_val, pred)\n",
    "    \n",
    "    acc_val_list.append(acc_val)\n",
    "    \n",
    "    # Testando o classificador (usando o conjunto de treino)\n",
    "    # **** Apenas para comparar com o resultado da validação ****\n",
    "    pred_train = clf.predict(X_train_2_norm)\n",
    "    acc_train = metrics.accuracy_score(y_train_2, pred_train)\n",
    "    \n",
    "    acc_train_list.append(acc_train)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af83404f-bb28-4700-8b10-2aad3b6927f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(9, 6))\n",
    "\n",
    "plt.plot(k_list, acc_train_list, 'o', color='blue', label='treino')\n",
    "plt.plot(k_list, acc_val_list, 'x', color='red', label='validação')\n",
    "plt.xlabel(\"Valor de 'k'\")\n",
    "plt.ylabel(\"Acurácia\")\n",
    "plt.legend(loc='best')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cca1718-5bcb-4b27-ac6c-c96238f48029",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('k \\t acc. train \\t acc. val')\n",
    "print('----------------------------')\n",
    "for k_, acc_t, acc_v in zip(k_list, acc_train_list, acc_val_list):\n",
    "    print(f'{k_} \\t {acc_t:.4f} \\t {acc_v:.4f}')\n",
    "\n",
    "k_best = k_list[np.argmax(acc_val_list)]\n",
    "print(f'\\nMelhor \\'k\\': {k_best} ({np.max(acc_val_list):.4f} acc.)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ed03c94-95bd-4df3-aa10-264713098ebf",
   "metadata": {},
   "source": [
    "## Evaluating the model over the test set\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b275e16d-d93b-49f1-99f8-3dc0b7e0e6f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constrói um classificador K-NN. K = k_best\n",
    "clf = neighbors.KNeighborsClassifier(n_neighbors=k_best)\n",
    "\n",
    "# Treinando o classificador\n",
    "clf.fit(X_train_2_norm, y_train_2)\n",
    "\n",
    "# Testando o classificador (usando o conjunto de TESTES)\n",
    "pred = clf.predict(X_test_norm)\n",
    "acc_val = metrics.accuracy_score(y_test, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c8b2ce4-abe4-49fb-ad20-5aaabd0933c2",
   "metadata": {},
   "source": [
    "### Confusion matrix and classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f47fe75-8e17-4c98-9273-710a0f2c9ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\nConfusion matrix:')\n",
    "print(metrics.confusion_matrix(y_test, pred))\n",
    "\n",
    "print('\\nClassification report:')\n",
    "print(metrics.classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f868ee3b-680b-486a-9f12-9761f88816a7",
   "metadata": {},
   "source": [
    "### A detailed classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40effb43-4fd2-4e23-b328-6c0e097d191b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (y_test_, pred_, filename_) in enumerate(zip(y_test, pred, file_test)):\n",
    "    print(f'{i} \\t {filename_} \\t {y_test_} \\t {pred_} \\t {(y_test_ == pred_)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4a544b8-bfd2-4387-b097-689de2597730",
   "metadata": {},
   "source": [
    "## Bibliography\n",
    "---\n",
    "* GONZALEZ, R.C.; WOODS, R.E. **Digital Image Processing.** 3rd ed. Pearson, 2007.\n",
    "* COSTA, L. DA F.; CESAR-JR., R. M. **Shape analysis and classification: theory and practice.** CRC Press, 2000. Chapter 8.\n",
    "* Scikit-image documentation.\n",
    "    * https://scikit-image.org/docs/stable/\n",
    "* scikit-learn - User Guide.\n",
    "    * https://scikit-learn.org/stable/user_guide.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env-sin393-cpu-py39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
